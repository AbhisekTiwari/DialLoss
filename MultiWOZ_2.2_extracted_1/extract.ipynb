{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "count=0\n",
    "\n",
    "with open('dialogues_001.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    # with open ('output.txt', 'w') as file:\n",
    "    with open ('sample.tsv','wt') as file:\n",
    "        tsv_writer = csv.writer(file, delimiter='\\t')\n",
    "        tsv_writer.writerow(['trg','src'])\n",
    "        for conversation in data:\n",
    "            services=conversation['services']\n",
    "            domain=\"<\"+\"><\".join(services)+\">\"\n",
    "            domain=f\"<domain> {domain} <domain>\"\n",
    "            dialogues=conversation['turns']\n",
    "            history=\"\"\n",
    "            dialogue_len=len(dialogues)\n",
    "            for iter,turn in enumerate(dialogues):\n",
    "                speaker=turn['speaker']\n",
    "                dialogue=turn['utterance']\n",
    "                if speaker==\"USER\":\n",
    "                    cur_utterance=f\"<cur_utterance> {dialogue} <cur_utterance>\"\n",
    "                    cur_history=f\"<history> {history} <history>\"\n",
    "                    if iter+1<dialogue_len :\n",
    "                        next_speaker=dialogues[iter+1]['speaker']\n",
    "                        if next_speaker==\"SYSTEM\":\n",
    "                            src=domain+\"\\t\"+cur_history+\"\\t\"+cur_utterance\n",
    "                            trg=dialogues[iter+1]['utterance']\n",
    "                            tsv_writer.writerow([src,trg])\n",
    "                    history+=f\"<u> {dialogue} <u>\"\n",
    "                elif speaker==\"SYSTEM\":\n",
    "                    history+=f\"<s> {dialogue} <s>\"\n",
    "            \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1243,  0.1850],\n",
      "        [ 0.1433, -0.2133]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "def cosine_similarity(output, target):\n",
    "    # output_tensor=torch.tensor(output,requires_grad=True)\n",
    "    output_tensor=output\n",
    "    target_tensor=torch.tensor(target)\n",
    "    loss = torch.dot(output_tensor,target_tensor)\n",
    "    loss = loss/(torch.norm(output_tensor)*torch.norm(target_tensor))\n",
    "    return loss\n",
    "\n",
    "model = nn.Linear(2, 2)\n",
    "x = torch.randn(2)\n",
    "target = torch.randn(2)\n",
    "target = target.numpy()\n",
    "# output = torch.randn(2)\n",
    "# output= output.numpy()\n",
    "output=model(x)\n",
    "loss = cosine_similarity(output, target)\n",
    "loss.backward()\n",
    "print(model.weight.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "def extract(actual_filename,tsv_writer):\n",
    "    with open(actual_filename) as data_file:    \n",
    "        data = json.load(data_file)\n",
    "        for conversation in data:\n",
    "            services=conversation['services']\n",
    "            domain=\",\".join(services)\n",
    "            domain=f\"<domain> {domain} <domain>\"\n",
    "            dialogues=conversation['turns']\n",
    "            history=\"\"\n",
    "            dialogue_len=len(dialogues)\n",
    "            for iter,turn in enumerate(dialogues):\n",
    "                speaker=turn['speaker']\n",
    "                dialogue=turn['utterance']\n",
    "                if speaker==\"USER\":\n",
    "                    cur_utterance=f\"<cur_utterance> {dialogue} <cur_utterance>\"\n",
    "                    cur_history=f\"<history> {history} <history>\"\n",
    "                    if iter+1<dialogue_len :\n",
    "                        next_speaker=dialogues[iter+1]['speaker']\n",
    "                        if next_speaker==\"SYSTEM\":\n",
    "                            src=domain+cur_history+cur_utterance #/t removed\n",
    "                            trg=dialogues[iter+1]['utterance']\n",
    "                            tsv_writer.writerow([src,trg])\n",
    "                    history+=f\"<u> {dialogue} <u>\"\n",
    "                elif speaker==\"SYSTEM\":\n",
    "                    history+=f\"<s> {dialogue} <s>\"\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code is ran at LE_S folder\n",
    "folder_list=['dev','test','train']\n",
    "# folder_list=['train']\n",
    "parent_directory='/mnt/Data/abhisek_1921cs16/R/CRW/1.NLG_LE/LE_S/Datasets/T/MultiWOZ_2.2/'\n",
    "for folder in folder_list:\n",
    "    with open (folder+'.tsv', 'w') as file:\n",
    "        tsv_writer = csv.writer(file, delimiter='\\t')\n",
    "        # tsv_writer.writerow(['src','trg'])\n",
    "        directory=parent_directory+folder\n",
    "        for filename in os.listdir(directory):\n",
    "            actual_filename=directory+'/'+filename \n",
    "            extract(actual_filename,tsv_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting in text file\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "def extract(actual_filename,src_file,trg_file):\n",
    "    with open(actual_filename) as data_file:    \n",
    "        data = json.load(data_file)\n",
    "        for conversation in data:\n",
    "            services=conversation['services']\n",
    "            domain=\",\".join(services)\n",
    "            domain=f\"<domain> {domain} <domain>\"\n",
    "            dialogues=conversation['turns']\n",
    "            history=\"\"\n",
    "            dialogue_len=len(dialogues)\n",
    "            for iter,turn in enumerate(dialogues):\n",
    "                speaker=turn['speaker']\n",
    "                dialogue=turn['utterance']\n",
    "                if speaker==\"USER\":\n",
    "                    cur_utterance=f\"<cur_utterance> {dialogue} <cur_utterance>\"\n",
    "                    cur_history=f\"<history> {history} <history>\"\n",
    "                    if iter+1<dialogue_len :\n",
    "                        next_speaker=dialogues[iter+1]['speaker']\n",
    "                        if next_speaker==\"SYSTEM\":\n",
    "                            src=domain+cur_history+cur_utterance #/t removed\n",
    "                            trg=dialogues[iter+1]['utterance']\n",
    "                            src_file.write(src+'\\n')\n",
    "                            trg_file.write(trg+'\\n')\n",
    "                    history+=f\"<u> {dialogue} <u>\"\n",
    "                elif speaker==\"SYSTEM\":\n",
    "                    history+=f\"<s> {dialogue} <s>\"\n",
    "                \n",
    "#this code is ran at LE_S folder\n",
    "folder_list=['dev','test','train']\n",
    "# folder_list=['train']\n",
    "parent_directory='/mnt/Data/abhisek_1921cs16/R/CRW/1.NLG_LE/LE_S/Datasets/T/MultiWOZ_2.2/'\n",
    "for folder in folder_list:\n",
    "    with open (folder+'_src.txt','w') as src_file, open (folder+'_trg.txt','w') as trg_file:\n",
    "        directory=parent_directory+folder\n",
    "        for filename in os.listdir(directory):\n",
    "            actual_filename=directory+'/'+filename \n",
    "            extract(actual_filename,src_file,trg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed file written: train.tsv.pre\n",
      "No. of lines truncated: 0\n",
      "Preprocessed file written: dev.tsv.pre\n",
      "No. of lines truncated: 0\n",
      "Preprocessed file written: test.tsv.pre\n",
      "No. of lines truncated: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.paste -d'\\t' src_file trg_file label_file > train.tsv\n",
    "import os \n",
    "files=['train','dev','test']\n",
    "# paste -d'\\t' train_src.txt train_trg.txt > train.tsv\n",
    "for file in files:\n",
    "    os.system(f\"paste -d'\\t' {file}_src.txt {file}_trg.txt > {file}.tsv\")\n",
    "os.system(\"python preprocess_parallel_corpus_labels.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "counts=[]\n",
    "# read data from file\n",
    "# interviews_df = pd.read_csv('train.tsv', sep='\\t')\n",
    "\n",
    "c=0\n",
    "# printing data)\n",
    "with open('dev.tsv') as file:\n",
    "    tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "    for line in tsv_file:\n",
    "        counts.append(len(line[0].split()))\n",
    "\n",
    "import numpy as np\n",
    "np.percentile(counts,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(cur,pattern):\n",
    "    return pattern+cur+pattern\n",
    "\n",
    "def extract_pattern(dialogue,pattern):\n",
    "    list=[]\n",
    "    flag=0\n",
    "    temp=\"\"\n",
    "    for index,i in enumerate(dialogue):\n",
    "        if dialogue[index:index+len(pattern)]==pattern:\n",
    "            if flag==0:\n",
    "                flag=1\n",
    "            else:\n",
    "                list.append(temp[len(pattern):])\n",
    "                temp=\"\"\n",
    "                flag=0\n",
    "        if flag:\n",
    "            temp+=i\n",
    "    return list\n",
    "\n",
    "def convert_to_last3(dialogue):\n",
    "    user=extract_pattern(dialogue,\"<u>\")\n",
    "    system=extract_pattern(dialogue,\"<s>\")\n",
    "    domain=extract_pattern(dialogue,\"<domain>\")\n",
    "    cur_utterance=extract_pattern(dialogue,\"<cur_utterance>\")\n",
    "    total=len(user)\n",
    "    user=user[-(min(3,total)):]\n",
    "    system=system[-min(3,total):]\n",
    "\n",
    "    new_dialogue=format(domain[0],\"<domain>\")\n",
    "    for cur_user,cur_system in zip(user,system):\n",
    "        new_dialogue+=format(cur_user,\"<u>\")\n",
    "        new_dialogue+=format(cur_system,\"<s>\")\n",
    "    new_dialogue+=\" <history>\"\n",
    "    new_dialogue+=format(cur_utterance[0],\"<cur_utterance>\")\n",
    "    return new_dialogue\n",
    "\n",
    "files=[\"dev\",\"train\",\"test\"]\n",
    "for file_name in files:\n",
    "    writer_file=file_name+\"_src1.txt\"\n",
    "    filename=file_name+\"_src.txt\"\n",
    "    with open(filename,\"r\") as reader,open(writer_file,\"w\") as writer:\n",
    "        for line in reader:\n",
    "            temp=convert_to_last3(line)\n",
    "            writer.write(temp+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9575\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "files=['dev_src.txt','train_src.txt','test_src.txt']\n",
    "count=0\n",
    "cur=\"\"\n",
    "def convert(text):\n",
    "    regex = r'<domain>(.*?)<domain>'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "for file in files:\n",
    "    with open(file,'r') as reader_file:\n",
    "        for line in reader_file:\n",
    "            temp=convert(line)\n",
    "            if temp!=cur:\n",
    "                count+=1\n",
    "                cur=temp\n",
    "print(count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c049cddf4d72298e1e7d53197f8627a7b2212b4ce4f37fbaf245cfc80c27bf25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
